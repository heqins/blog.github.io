<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://heqins.github.io</id>
    <title>Gridea</title>
    <updated>2023-09-14T08:53:37.768Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://heqins.github.io"/>
    <link rel="self" href="https://heqins.github.io/atom.xml"/>
    <subtitle>æ¸©æ•…è€ŒçŸ¥æ–°</subtitle>
    <logo>https://heqins.github.io/images/avatar.png</logo>
    <icon>https://heqins.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[Hadoop - MapReduceæ¶æ„è¯¦è§£]]></title>
        <id>https://heqins.github.io/post/ce-shi/</id>
        <link href="https://heqins.github.io/post/ce-shi/">
        </link>
        <updated>2023-09-14T07:25:39.000Z</updated>
        <content type="html"><![CDATA[<h2 id="mapreduceæ‰§è¡Œæ•´ä½“æ¶æ„">MapReduceæ‰§è¡Œæ•´ä½“æ¶æ„</h2>
<figure data-type="image" tabindex="1"><img src="https://heqins.github.io/post-images/1694679458961.jpg" alt="" loading="lazy"></figure>
<p>è¿™é‡Œå…ˆè´´ä¸€ä¸‹è®ºæ–‡é‡Œçš„åŸè¯ï¼š</p>
<pre><code>The MapReduce library in the user program first
splits the input files into M pieces of typically 16
megabytes to 64 megabytes (MB) per piece (controllable by the user via an optional parameter). It
then starts up many copies of the program on a cluster of machines.

2. One of the copies of the program is special â€“ the
master. The rest are workers that are assigned work
by the master. There are M map tasks and R reduce
tasks to assign. The master picks idle workers and
assigns each one a map task or a reduce task.

3. A worker who is assigned a map task reads the
contents of the corresponding input split. It parses
key/value pairs out of the input data and passes each
pair to the user-defined Map function. The intermediate key/value pairs produced by the Map function
are buffered in memory.

4. Periodically, the buffered pairs are written to local
disk, partitioned into R regions by the partitioning
function. The locations of these buffered pairs on
the local disk are passed back to the master, who
is responsible for forwarding these locations to the
reduce workers.

5. When a reduce worker is notified by the master
about these locations, it uses remote procedure calls
to read the buffered data from the local disks of the
map workers. When a reduce worker has read all intermediate data, it sorts it by the intermediate keys
so that all occurrences of the same key are grouped
together. The sorting is needed because typically
many different keys map to the same reduce task. If
the amount of intermediate data is too large to fit in
memory, an external sort is used.

6. The reduce worker iterates over the sorted intermediate data and for each unique intermediate key encountered, it passes the key and the corresponding
set of intermediate values to the userâ€™s Reduce function. The output of the Reduce function is appended
to a final output file for this reduce partition.
</code></pre>
<p>ç®€å•ç†è§£ä¸€ä¸‹ï¼Œé¦–å…ˆç”¨æˆ·Clientå°†è¾“å…¥æ•°æ®åˆ‡åˆ†ä¸ºå¤šä¸ªå—ï¼Œä¸åŒçš„workerèŠ‚ç‚¹è¯»å–æ‰€æœ‰åˆ‡å—çš„è¾“å…¥æ•°æ®ï¼Œæ ¹æ®ç”¨æˆ·æŒ‡å®šçš„map functioè¿›è¡Œæ˜ å°„æ“ä½œï¼Œäº§ç”Ÿkey/valueé”®å€¼å¯¹å¹¶å†™å…¥åˆ°æœ¬åœ°çš„ä¸´æ—¶æ–‡ä»¶ä¸­ï¼›workeréšåå°†è¿™äº›é”®å€¼å¯¹æ–‡ä»¶çš„ä¿¡æ¯å‘é€ç»™masterï¼Œmasteréšå³é€šçŸ¥ç»™ä¸ªè´Ÿè´£æ‰§è¡Œreduce taskçš„workerï¼Œworkeré€šè¿‡è¿œç¨‹ä¼ è¾“çš„æ–¹å¼è¯»å–map taskæ‰€åœ¨èŠ‚ç‚¹ä¸Šçš„è¿™äº›æ–‡ä»¶ï¼Œreduce workerè¯»å–æ•°æ®å®Œæ¯•åæ‰§è¡Œsortæ“ä½œï¼Œå°†æ‰€æœ‰æ‹¥æœ‰ç›¸åŒkeyçš„é”®å€¼å¯¹ï¼ˆå½¢å¦‚&lt;key,List<Value>&gt;ï¼‰æ”¾åœ¨ä¸€èµ·ã€‚éšåreduce workeræ‰§è¡Œç”¨æˆ·å®šä¹‰çš„reduce functionå¹¶å°†åˆå¹¶ç»“æœè¾“å‡ºåˆ°æŒ‡å®šçš„æ–‡ä»¶ä¸­</p>
<h3 id="map-workerå’Œreduce-workeræ˜¯å›ºå®šè¿˜æ˜¯æ¯æ¬¡éšå³åˆ†é…çš„">map workerå’Œreduce workeræ˜¯å›ºå®šè¿˜æ˜¯æ¯æ¬¡éšå³åˆ†é…çš„ï¼Ÿ</h3>
<p>åœ¨ Hadoop ä¸­ï¼ŒMapReduce ä»»åŠ¡çš„æ‰§è¡Œæ¶‰åŠåˆ° Master èŠ‚ç‚¹ï¼ˆä¾‹å¦‚ï¼ŒJobTracker æˆ– ResourceManagerï¼‰å’Œ Worker èŠ‚ç‚¹ï¼ˆä¾‹å¦‚ï¼ŒTaskTracker æˆ– NodeManagerï¼‰ï¼Œå®ƒä»¬çš„è§’è‰²æ˜¯å›ºå®šçš„ï¼Œä½†å…·ä½“çš„å®ä¾‹å¯ä»¥æ˜¯åŠ¨æ€å˜åŒ–çš„ã€‚</p>
<p><strong>Master èŠ‚ç‚¹ï¼š</strong><br>
åœ¨ Hadoop 1.0 ç‰ˆæœ¬ä¸­ï¼Œæœ‰ä¸€ä¸ª JobTracker è´Ÿè´£ç®¡ç† MapReduce ä½œä¸šçš„æ‰§è¡Œã€‚è¿™ä¸ª JobTracker å®ä¾‹é€šå¸¸æ˜¯åœ¨é›†ç¾¤å¯åŠ¨æ—¶å¯åŠ¨çš„ï¼Œè€Œä¸”åœ¨æ•´ä¸ªé›†ç¾¤ç”Ÿå‘½å‘¨æœŸå†…æ˜¯å›ºå®šçš„ã€‚</p>
<p>åœ¨ Hadoop 2.x ç‰ˆæœ¬ä»¥åï¼Œå¼•å…¥äº† ResourceManagerï¼Œå®ƒè´Ÿè´£é›†ç¾¤çš„èµ„æºç®¡ç†ã€‚ä¸ JobTracker ä¸åŒï¼ŒResourceManager æ˜¯ä¸€ä¸ªé•¿æœŸè¿è¡Œçš„æœåŠ¡ï¼Œä¹Ÿæ˜¯é›†ç¾¤å¯åŠ¨æ—¶å¯åŠ¨çš„ï¼Œé€šå¸¸æ˜¯å›ºå®šçš„ã€‚<br>
ApplicationMaster æ˜¯ç®¡ç†æ¯ä¸ªä½œä¸šçš„æ‰§è¡Œçš„ç»„ä»¶ï¼Œæ¯ä¸ªä½œä¸šéƒ½æœ‰ä¸€ä¸ªç‹¬ç«‹çš„ ApplicationMaster å®ä¾‹ï¼Œç”± ResourceManager åˆ†é…ã€‚å› æ­¤ï¼ŒApplicationMaster çš„å®ä¾‹æ•°ä¼šæ ¹æ®ä½œä¸šçš„æ•°é‡åŠ¨æ€å˜åŒ–ã€‚</p>
<p><strong>Worker èŠ‚ç‚¹ï¼š</strong><br>
åœ¨ Hadoop 1.0 ç‰ˆæœ¬ä¸­ï¼Œæœ‰å¤šä¸ª TaskTracker å®ä¾‹ï¼Œæ¯ä¸ª TaskTracker è´Ÿè´£æ‰§è¡Œ Map å’Œ Reduce ä»»åŠ¡ã€‚è¿™äº› TaskTracker å®ä¾‹åœ¨é›†ç¾¤èŠ‚ç‚¹ä¸Šè¿è¡Œï¼Œå¹¶ä¸”åœ¨æ•´ä¸ªé›†ç¾¤ç”Ÿå‘½å‘¨æœŸå†…æ˜¯å›ºå®šçš„ï¼Œå®ƒä»¬ä¸€ç›´ç›‘å¬ä»»åŠ¡åˆ†é…ã€‚</p>
<p>åœ¨ Hadoop 2.x ç‰ˆæœ¬ä»¥åï¼Œæœ‰å¤šä¸ª NodeManager å®ä¾‹ï¼Œæ¯ä¸ª NodeManager è´Ÿè´£ç®¡ç†èŠ‚ç‚¹ä¸Šçš„å®¹å™¨ï¼Œå…¶ä¸­åŒ…æ‹¬è¿è¡Œ Map å’Œ Reduce ä»»åŠ¡çš„å®¹å™¨ã€‚ä¸ TaskTracker ä¸åŒï¼ŒNodeManager æ˜¯ä¸€ä¸ªé•¿æœŸè¿è¡Œçš„æœåŠ¡ï¼Œä¼šä¸€ç›´ç›‘å¬èµ„æºç®¡ç†å™¨çš„æŒ‡ä»¤ã€‚</p>
<p>æ€»çš„æ¥è¯´ï¼ŒMaster èŠ‚ç‚¹çš„å®ä¾‹é€šå¸¸æ˜¯å›ºå®šçš„ï¼Œè€Œ Worker èŠ‚ç‚¹çš„å®ä¾‹ä¼šåŠ¨æ€å˜åŒ–ï¼Œæ ¹æ®ä½œä¸šçš„éœ€æ±‚åˆ†é…ä»»åŠ¡ã€‚åœ¨ Hadoop 2.x ç‰ˆæœ¬ä»¥åï¼Œå¼•å…¥äº†æ›´çµæ´»çš„èµ„æºç®¡ç†å’Œä»»åŠ¡æ‰§è¡Œæ¨¡å‹ï¼Œæé«˜äº†é›†ç¾¤çš„å¯ä¼¸ç¼©æ€§å’Œæ•ˆç‡ã€‚</p>
<h3 id="combineræ˜¯ä»€ä¹ˆ">combineræ˜¯ä»€ä¹ˆï¼Ÿ</h3>
<p>åœ¨ Hadoop å’Œ MapReduce ç¼–ç¨‹æ¨¡å‹ä¸­ï¼ŒCombinerï¼ˆåˆå¹¶å™¨ï¼‰æ˜¯ä¸€ç§ç”¨äºä¼˜åŒ–æ•°æ®å¤„ç†çš„ä¸­é—´æ­¥éª¤ã€‚Combiner å¯ä»¥åœ¨æ•°æ®è¢«ä¼ è¾“åˆ° Reduce é˜¶æ®µä¹‹å‰ï¼Œåœ¨ Map é˜¶æ®µå¯¹éƒ¨åˆ†æ•°æ®è¿›è¡Œæœ¬åœ°åˆå¹¶å’Œæ±‡æ€»ã€‚å…¶ä¸»è¦ç›®çš„æ˜¯å‡å°‘æ•°æ®ä¼ è¾“å’Œé™ä½ç½‘ç»œå¼€é”€ï¼Œä»¥æé«˜ MapReduce ä½œä¸šçš„æ€§èƒ½ã€‚</p>
<p><strong>Combiner çš„å·¥ä½œåŸç†å¦‚ä¸‹ï¼š</strong></p>
<p>Map é˜¶æ®µï¼šåœ¨ Map é˜¶æ®µï¼ŒMapper ä»»åŠ¡ç”Ÿæˆé”®å€¼å¯¹ï¼ˆkey-value pairsï¼‰ä½œä¸ºè¾“å‡ºï¼Œè¿™äº›é”®å€¼å¯¹é€šå¸¸æ˜¯æ— åºçš„ã€‚<br>
Combiner é˜¶æ®µï¼šCombiner æ˜¯ä¸€ä¸ªå¯é€‰çš„ä¸­é—´æ­¥éª¤ï¼Œå®ƒåœ¨ Map ä»»åŠ¡æœ¬åœ°å¯¹ Mapper è¾“å‡ºçš„é”®å€¼å¯¹è¿›è¡Œåˆå¹¶å’Œæ±‡æ€»ã€‚Combiner æ¥æ”¶ç›¸åŒé”®çš„å¤šä¸ªå€¼ï¼Œå¹¶å°†å®ƒä»¬åˆå¹¶ä¸ºä¸€ä¸ªæˆ–å¤šä¸ªé”®å€¼å¯¹ã€‚è¿™ä¸ªè¿‡ç¨‹æ˜¯åœ¨ Mapper ä»»åŠ¡çš„æœ¬åœ°æ‰§è¡Œçš„ï¼Œä¸æ¶‰åŠç½‘ç»œä¼ è¾“ã€‚<br>
Shuffle å’Œ Sort é˜¶æ®µï¼šç»è¿‡ Combiner é˜¶æ®µçš„å¤„ç†åï¼Œæ•°æ®è¿›å…¥ Shuffle å’Œ Sort é˜¶æ®µã€‚åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæ•°æ®è¢«åˆ†åŒºã€æ’åºå¹¶ä¼ è¾“åˆ° Reduce ä»»åŠ¡ã€‚<br>
Reduce é˜¶æ®µï¼šåœ¨ Reduce é˜¶æ®µï¼Œæ•°æ®å†æ¬¡æŒ‰ç…§é”®è¿›è¡Œåˆ†ç»„ï¼Œå¹¶ä¼ é€’ç»™ Reduce å‡½æ•°è¿›è¡Œè¿›ä¸€æ­¥çš„å¤„ç†ã€‚</p>
<p><strong>Combiner çš„ä¸»è¦ä¼˜ç‚¹åŒ…æ‹¬ï¼š</strong></p>
<p>å‡å°‘æ•°æ®ä¼ è¾“ï¼šç”±äº Combiner åœ¨ Map ä»»åŠ¡æœ¬åœ°æ‰§è¡Œåˆå¹¶ï¼Œå®ƒå¯ä»¥å¤§å¹…å‡å°‘éœ€è¦ä¼ è¾“åˆ° Reduce ä»»åŠ¡çš„æ•°æ®é‡ï¼Œé™ä½äº†ç½‘ç»œå¼€é”€ã€‚<br>
é™ä½ Reduce ä»»åŠ¡è´Ÿè½½ï¼šCombiner å¯ä»¥åœ¨ Map é˜¶æ®µå°±è¿›è¡Œéƒ¨åˆ†èšåˆï¼Œä»è€Œé™ä½äº† Reduce ä»»åŠ¡çš„å·¥ä½œé‡ï¼Œæé«˜äº†æ•´ä½“æ€§èƒ½ã€‚<br>
æé«˜ä½œä¸šæ€§èƒ½ï¼šé€šè¿‡å‡å°‘æ•°æ®ä¼ è¾“å’Œé™ä½ Reduce ä»»åŠ¡çš„è´Ÿè½½ï¼ŒCombiner å¯ä»¥æ˜¾è‘—æé«˜ MapReduce ä½œä¸šçš„æ€§èƒ½ã€‚</p>
<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒCombiner åªé€‚ç”¨äºæ»¡è¶³ç»“åˆå¾‹ï¼ˆAssociativeï¼‰å’Œå¯äº¤æ¢å¾‹ï¼ˆCommutativeï¼‰çš„æ“ä½œï¼Œå› ä¸ºå®ƒæ‰§è¡Œçš„æ˜¯å±€éƒ¨åˆå¹¶ã€‚ä¸é€‚ç”¨äºæ‰€æœ‰æƒ…å†µï¼Œå› æ­¤åœ¨åº”ç”¨ Combiner æ—¶éœ€è¦è°¨æ…é€‰æ‹©åˆé€‚çš„æ“ä½œã€‚ Combiner æ˜¯ MapReduce ç¼–ç¨‹ä¸­çš„ä¸€ç§æ€§èƒ½ä¼˜åŒ–å·¥å…·ï¼Œå¯ä»¥æ ¹æ®å…·ä½“çš„ä½œä¸šå’Œæ•°æ®ç‰¹æ€§æ¥å†³å®šæ˜¯å¦ä½¿ç”¨ä»¥åŠå¦‚ä½•ä½¿ç”¨ã€‚</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://heqins.github.io/post/hello-gridea/</id>
        <link href="https://heqins.github.io/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>ğŸ‘  æ¬¢è¿ä½¿ç”¨ <strong>Gridea</strong> ï¼<br>
âœï¸  <strong>Gridea</strong> ä¸€ä¸ªé™æ€åšå®¢å†™ä½œå®¢æˆ·ç«¯ã€‚ä½ å¯ä»¥ç”¨å®ƒæ¥è®°å½•ä½ çš„ç”Ÿæ´»ã€å¿ƒæƒ…ã€çŸ¥è¯†ã€ç¬”è®°ã€åˆ›æ„... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>ğŸ‘  æ¬¢è¿ä½¿ç”¨ <strong>Gridea</strong> ï¼<br>
âœï¸  <strong>Gridea</strong> ä¸€ä¸ªé™æ€åšå®¢å†™ä½œå®¢æˆ·ç«¯ã€‚ä½ å¯ä»¥ç”¨å®ƒæ¥è®°å½•ä½ çš„ç”Ÿæ´»ã€å¿ƒæƒ…ã€çŸ¥è¯†ã€ç¬”è®°ã€åˆ›æ„... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea ä¸»é¡µ</a><br>
<a href="https://fehey.com/">ç¤ºä¾‹ç½‘ç«™</a></p>
<h2 id="ç‰¹æ€§">ç‰¹æ€§ğŸ‘‡</h2>
<p>ğŸ“  ä½ å¯ä»¥ä½¿ç”¨æœ€é…·çš„ <strong>Markdown</strong> è¯­æ³•ï¼Œè¿›è¡Œå¿«é€Ÿåˆ›ä½œ</p>
<p>ğŸŒ‰  ä½ å¯ä»¥ç»™æ–‡ç« é…ä¸Šç²¾ç¾çš„å°é¢å›¾å’Œåœ¨æ–‡ç« ä»»æ„ä½ç½®æ’å…¥å›¾ç‰‡</p>
<p>ğŸ·ï¸  ä½ å¯ä»¥å¯¹æ–‡ç« è¿›è¡Œæ ‡ç­¾åˆ†ç»„</p>
<p>ğŸ“‹  ä½ å¯ä»¥è‡ªå®šä¹‰èœå•ï¼Œç”šè‡³å¯ä»¥åˆ›å»ºå¤–éƒ¨é“¾æ¥èœå•</p>
<p>ğŸ’»  ä½ å¯ä»¥åœ¨ <strong>Windows</strong>ï¼Œ<strong>MacOS</strong> æˆ– <strong>Linux</strong> è®¾å¤‡ä¸Šä½¿ç”¨æ­¤å®¢æˆ·ç«¯</p>
<p>ğŸŒ  ä½ å¯ä»¥ä½¿ç”¨ <strong>ğ–¦ğ—‚ğ—ğ—ğ—ğ–» ğ–¯ğ–ºğ—€ğ–¾ğ—Œ</strong> æˆ– <strong>Coding Pages</strong> å‘ä¸–ç•Œå±•ç¤ºï¼Œæœªæ¥å°†æ”¯æŒæ›´å¤šå¹³å°</p>
<p>ğŸ’¬  ä½ å¯ä»¥è¿›è¡Œç®€å•çš„é…ç½®ï¼Œæ¥å…¥ <a href="https://github.com/gitalk/gitalk">Gitalk</a> æˆ– <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> è¯„è®ºç³»ç»Ÿ</p>
<p>ğŸ‡¬ğŸ‡§  ä½ å¯ä»¥ä½¿ç”¨<strong>ä¸­æ–‡ç®€ä½“</strong>æˆ–<strong>è‹±è¯­</strong></p>
<p>ğŸŒ  ä½ å¯ä»¥ä»»æ„ä½¿ç”¨åº”ç”¨å†…é»˜è®¤ä¸»é¢˜æˆ–ä»»æ„ç¬¬ä¸‰æ–¹ä¸»é¢˜ï¼Œå¼ºå¤§çš„ä¸»é¢˜è‡ªå®šä¹‰èƒ½åŠ›</p>
<p>ğŸ–¥  ä½ å¯ä»¥è‡ªå®šä¹‰æºæ–‡ä»¶å¤¹ï¼Œåˆ©ç”¨ OneDriveã€ç™¾åº¦ç½‘ç›˜ã€iCloudã€Dropbox ç­‰è¿›è¡Œå¤šè®¾å¤‡åŒæ­¥</p>
<p>ğŸŒ± å½“ç„¶ <strong>Gridea</strong> è¿˜å¾ˆå¹´è½»ï¼Œæœ‰å¾ˆå¤šä¸è¶³ï¼Œä½†è¯·ç›¸ä¿¡ï¼Œå®ƒä¼šä¸åœå‘å‰ ğŸƒ</p>
<p>æœªæ¥ï¼Œå®ƒä¸€å®šä¼šæˆä¸ºä½ ç¦»ä¸å¼€çš„ä¼™ä¼´</p>
<p>å°½æƒ…å‘æŒ¥ä½ çš„æ‰åå§ï¼</p>
<p>ğŸ˜˜ Enjoy~</p>
]]></content>
    </entry>
</feed>