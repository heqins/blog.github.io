<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://heqins.github.io</id>
    <title>Gridea</title>
    <updated>2023-09-14T08:53:37.768Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://heqins.github.io"/>
    <link rel="self" href="https://heqins.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://heqins.github.io/images/avatar.png</logo>
    <icon>https://heqins.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[Hadoop - MapReduce架构详解]]></title>
        <id>https://heqins.github.io/post/ce-shi/</id>
        <link href="https://heqins.github.io/post/ce-shi/">
        </link>
        <updated>2023-09-14T07:25:39.000Z</updated>
        <content type="html"><![CDATA[<h2 id="mapreduce执行整体架构">MapReduce执行整体架构</h2>
<figure data-type="image" tabindex="1"><img src="https://heqins.github.io/post-images/1694679458961.jpg" alt="" loading="lazy"></figure>
<p>这里先贴一下论文里的原话：</p>
<pre><code>The MapReduce library in the user program first
splits the input files into M pieces of typically 16
megabytes to 64 megabytes (MB) per piece (controllable by the user via an optional parameter). It
then starts up many copies of the program on a cluster of machines.

2. One of the copies of the program is special – the
master. The rest are workers that are assigned work
by the master. There are M map tasks and R reduce
tasks to assign. The master picks idle workers and
assigns each one a map task or a reduce task.

3. A worker who is assigned a map task reads the
contents of the corresponding input split. It parses
key/value pairs out of the input data and passes each
pair to the user-defined Map function. The intermediate key/value pairs produced by the Map function
are buffered in memory.

4. Periodically, the buffered pairs are written to local
disk, partitioned into R regions by the partitioning
function. The locations of these buffered pairs on
the local disk are passed back to the master, who
is responsible for forwarding these locations to the
reduce workers.

5. When a reduce worker is notified by the master
about these locations, it uses remote procedure calls
to read the buffered data from the local disks of the
map workers. When a reduce worker has read all intermediate data, it sorts it by the intermediate keys
so that all occurrences of the same key are grouped
together. The sorting is needed because typically
many different keys map to the same reduce task. If
the amount of intermediate data is too large to fit in
memory, an external sort is used.

6. The reduce worker iterates over the sorted intermediate data and for each unique intermediate key encountered, it passes the key and the corresponding
set of intermediate values to the user’s Reduce function. The output of the Reduce function is appended
to a final output file for this reduce partition.
</code></pre>
<p>简单理解一下，首先用户Client将输入数据切分为多个块，不同的worker节点读取所有切块的输入数据，根据用户指定的map functio进行映射操作，产生key/value键值对并写入到本地的临时文件中；worker随后将这些键值对文件的信息发送给master，master随即通知给个负责执行reduce task的worker，worker通过远程传输的方式读取map task所在节点上的这些文件，reduce worker读取数据完毕后执行sort操作，将所有拥有相同key的键值对（形如&lt;key,List<Value>&gt;）放在一起。随后reduce worker执行用户定义的reduce function并将合并结果输出到指定的文件中</p>
<h3 id="map-worker和reduce-worker是固定还是每次随即分配的">map worker和reduce worker是固定还是每次随即分配的？</h3>
<p>在 Hadoop 中，MapReduce 任务的执行涉及到 Master 节点（例如，JobTracker 或 ResourceManager）和 Worker 节点（例如，TaskTracker 或 NodeManager），它们的角色是固定的，但具体的实例可以是动态变化的。</p>
<p><strong>Master 节点：</strong><br>
在 Hadoop 1.0 版本中，有一个 JobTracker 负责管理 MapReduce 作业的执行。这个 JobTracker 实例通常是在集群启动时启动的，而且在整个集群生命周期内是固定的。</p>
<p>在 Hadoop 2.x 版本以后，引入了 ResourceManager，它负责集群的资源管理。与 JobTracker 不同，ResourceManager 是一个长期运行的服务，也是集群启动时启动的，通常是固定的。<br>
ApplicationMaster 是管理每个作业的执行的组件，每个作业都有一个独立的 ApplicationMaster 实例，由 ResourceManager 分配。因此，ApplicationMaster 的实例数会根据作业的数量动态变化。</p>
<p><strong>Worker 节点：</strong><br>
在 Hadoop 1.0 版本中，有多个 TaskTracker 实例，每个 TaskTracker 负责执行 Map 和 Reduce 任务。这些 TaskTracker 实例在集群节点上运行，并且在整个集群生命周期内是固定的，它们一直监听任务分配。</p>
<p>在 Hadoop 2.x 版本以后，有多个 NodeManager 实例，每个 NodeManager 负责管理节点上的容器，其中包括运行 Map 和 Reduce 任务的容器。与 TaskTracker 不同，NodeManager 是一个长期运行的服务，会一直监听资源管理器的指令。</p>
<p>总的来说，Master 节点的实例通常是固定的，而 Worker 节点的实例会动态变化，根据作业的需求分配任务。在 Hadoop 2.x 版本以后，引入了更灵活的资源管理和任务执行模型，提高了集群的可伸缩性和效率。</p>
<h3 id="combiner是什么">combiner是什么？</h3>
<p>在 Hadoop 和 MapReduce 编程模型中，Combiner（合并器）是一种用于优化数据处理的中间步骤。Combiner 可以在数据被传输到 Reduce 阶段之前，在 Map 阶段对部分数据进行本地合并和汇总。其主要目的是减少数据传输和降低网络开销，以提高 MapReduce 作业的性能。</p>
<p><strong>Combiner 的工作原理如下：</strong></p>
<p>Map 阶段：在 Map 阶段，Mapper 任务生成键值对（key-value pairs）作为输出，这些键值对通常是无序的。<br>
Combiner 阶段：Combiner 是一个可选的中间步骤，它在 Map 任务本地对 Mapper 输出的键值对进行合并和汇总。Combiner 接收相同键的多个值，并将它们合并为一个或多个键值对。这个过程是在 Mapper 任务的本地执行的，不涉及网络传输。<br>
Shuffle 和 Sort 阶段：经过 Combiner 阶段的处理后，数据进入 Shuffle 和 Sort 阶段。在这个阶段，数据被分区、排序并传输到 Reduce 任务。<br>
Reduce 阶段：在 Reduce 阶段，数据再次按照键进行分组，并传递给 Reduce 函数进行进一步的处理。</p>
<p><strong>Combiner 的主要优点包括：</strong></p>
<p>减少数据传输：由于 Combiner 在 Map 任务本地执行合并，它可以大幅减少需要传输到 Reduce 任务的数据量，降低了网络开销。<br>
降低 Reduce 任务负载：Combiner 可以在 Map 阶段就进行部分聚合，从而降低了 Reduce 任务的工作量，提高了整体性能。<br>
提高作业性能：通过减少数据传输和降低 Reduce 任务的负载，Combiner 可以显著提高 MapReduce 作业的性能。</p>
<p>需要注意的是，Combiner 只适用于满足结合律（Associative）和可交换律（Commutative）的操作，因为它执行的是局部合并。不适用于所有情况，因此在应用 Combiner 时需要谨慎选择合适的操作。 Combiner 是 MapReduce 编程中的一种性能优化工具，可以根据具体的作业和数据特性来决定是否使用以及如何使用。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://heqins.github.io/post/hello-gridea/</id>
        <link href="https://heqins.github.io/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="https://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>